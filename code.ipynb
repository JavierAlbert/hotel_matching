{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agoda.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "g-4EKboJ6gb4",
        "cRN1BfgoUKo-",
        "7Ht-nmSEif3-",
        "gZRruM0PFLTD",
        "o-NPwmerv4hf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "g-4EKboJ6gb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data"
      ]
    },
    {
      "metadata": {
        "id": "zDOxVLG3zZFg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MagSl3y6gnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install PyDrive\n",
        "#!pip install seaborn\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gKGnl8-r0e9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kwL77Kwn0zwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3qw3fyHM3-q5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import partner1 data\n",
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':\"1i03d8w4qnex4GlyXj12caaosHCGrpmej\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('partner1.xlsx') \n",
        "partner1 = pd.read_excel('partner1.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6kPHUT002tJI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import partner2 data\n",
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':\"1EWAO7c700XTshY7MhMt-BcsUWlACjKu4\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('partner2.xlsx') \n",
        "partner2 = pd.read_excel('partner2.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jEe3HiuP4qTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import example data\n",
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':\"1JaZukEjWt_EqDVjvcmFOmdz__opIMOlw\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('example.xlsx') \n",
        "example = pd.read_excel('example.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OflRNsGFEKOL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Change column names of partner1 and partner2 dataframes\n",
        "partner1.columns = ['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']\n",
        "partner2.columns = ['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tGh6y0Sq68v_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split into example1 and example2, standarize column names\n",
        "example1 = example[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "example1.columns = ['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']\n",
        "example2 = example[['p2.key', 'p2.hotel_name', 'p2.city_name', 'p2.country_code', 'p2.hotel_address', 'p2.star_rating', 'p2.postal_code']]\n",
        "example2.columns = ['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kfN-_hsrg07j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing and Filtering"
      ]
    },
    {
      "metadata": {
        "id": "ykArIKVjuMNr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unifiy the datasets adn initialize final dataframe"
      ]
    },
    {
      "metadata": {
        "id": "q8ukDMc8uLlk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1 = partner1.append(example1)\n",
        "unified2 = partner2.append(example2)\n",
        "matched = pd.DataFrame(columns = ['key', 'predicted_key'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YHJquItk0ZvS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Quick look"
      ]
    },
    {
      "metadata": {
        "id": "EEYtv6ib0rcs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that our data is mostly full. Hotel name has no missing values on any of the datasets. We see that partner1 has more duplicated hotel names than partner2. "
      ]
    },
    {
      "metadata": {
        "id": "lBb3330b0bgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1.describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NPAO1rl40fR6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2.describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "to5fru4_mKvq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Duplicate keys?"
      ]
    },
    {
      "metadata": {
        "id": "l_5CIKgZmNU7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unified1\n",
        "unified1[unified1.duplicated(subset=['key'], keep=False)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5qpK2WFMmZh7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unified2\n",
        "unified2[unified2.duplicated(subset=['key'], keep=False)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X1KFJ2BtmdqG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Duplicate name and hotel?"
      ]
    },
    {
      "metadata": {
        "id": "6znUpqfNfaDI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see if we have duplicates (we define duplicates as same hotel name, city code and country). If we do and they are not so many let's manually match them and take them out of the game."
      ]
    },
    {
      "metadata": {
        "id": "7wobFdVee20A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unified1. We have a perfect duplicate, let's get rid of it.\n",
        "unified1[unified1.duplicated(subset=['hotel_name', 'city_name', 'country_code'], keep=False)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYsycv46flS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Unified2. We see 2 hotels with the same name, city and country but they seem to be 2 different hotels.\n",
        "unified2[unified2.duplicated(subset=['hotel_name', 'city_name', 'country_code'], keep=False)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xg2tK_rTgZVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's check if we can find hotels with that name un Unified1\n",
        "unified1[unified1['hotel_name']=='Comfort Inn Lincoln']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PxoitME1hyt-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We have our first match. Let's take it out of the unified1 and unified2 dataframes\n",
        "# and save it to the matched dataframe\n",
        "unified1 = unified1.drop(unified1.index[[508,664]])\n",
        "unified1 = unified1.reset_index(drop=True)\n",
        "unified2 = unified2.drop(unified2.index[8540])\n",
        "unified2 = unified2.reset_index(drop=True)\n",
        "\n",
        "d = {'key': ['EF00463C2A4279D9D58D452CB713906B'], 'predicted_key': ['C22A4FFCF0BB6E0CAB25E7AE4501E4BD']}\n",
        "row = pd.DataFrame(data=d)\n",
        "matched = matched.append(row)\n",
        "matched.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ogiSxgGbzYGs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hotel Country"
      ]
    },
    {
      "metadata": {
        "id": "gODAWeS8zzwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that few countries concentrate most of the data. They are US, TH, CN, IN, ID, JP, AU, VN, GB and more. Some intuition tells us that we may probably need to focus on those mostly."
      ]
    },
    {
      "metadata": {
        "id": "Md7ADfzozavJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1_grouped = unified1.groupby(['country_code']).count().reset_index()\n",
        "unified1_grouped.sort_values('key', ascending=False, inplace=True)\n",
        "plt.figure(figsize = (30,7))\n",
        "sns.barplot(x='country_code',y='key', data = unified1_grouped, edgecolor=\".1\").set_title('Number of datapoints by country in Unified1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "doWo310bzsoQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2_grouped = unified2.groupby(['country_code']).count().reset_index()\n",
        "unified2_grouped.sort_values('key', ascending=False, inplace=True)\n",
        "plt.figure(figsize = (30,7))\n",
        "sns.barplot(x='country_code',y='key', data = unified2_grouped, edgecolor=\".1\").set_title('Number of datapoints by country in Unified2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MXaEe-yIDd6M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are some datapoints in both partners that have no country code. Let's have a look at them, match them if we can and delete them from our dataset."
      ]
    },
    {
      "metadata": {
        "id": "rLtdRJtrDdOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1[unified1['country_code'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "orK0N-RiDxf-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2[unified2['country_code'].isnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ig7zX8hD-tK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# They all have a matching pair, let's add them to out matched dataframe\n",
        "unified1 = unified1.drop(unified1.index[[4782,5733,6064,9774,9894]])\n",
        "unified2 = unified2.drop(unified2.index[[1303,3134,5699,7776,9671]])\n",
        "\n",
        "d = {'key': ['0AC418BC2D45A6B8518096F1F00AF00F', 'C8A0A5B634A67365D57AB0983E601C62',\n",
        "             '4B36DF6237887FEE1B7A51FFF8F5F79F', 'CBE71D01B60AF5E074935BCE2F434AF4', \n",
        "             'F5782D38E38BE92661FC2A38A65335F1'], \n",
        "     'predicted_key': ['437A055FE6E759CCA7269E9F3AFAAA1B', '05E782BCA41AB39ED4F6602C9E54BAA8', \n",
        "                       'AEA31679E9873B89508E6A95DF23BBD8', '5256D45F46338BFFA68B84A7BEC99146', \n",
        "                       '9590C8BC8A30858FE272F3A08AD04173']}\n",
        "\n",
        "row = pd.DataFrame(data=d)\n",
        "matched = matched.append(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "we68aeFZNdI2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched.reset_index(drop=True, inplace=True)\n",
        "matched.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dCWM-mmOzL4s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hotel postal_code"
      ]
    },
    {
      "metadata": {
        "id": "X4JlfZuHxKDW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1['postal_code'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zQ7LXZ_2xOL-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2['postal_code'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aDt3Shfg0I9Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hotel City"
      ]
    },
    {
      "metadata": {
        "id": "iLlQfyiE0QWZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1['city_name'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ywn20Sfi1H62",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2['city_name'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xS-YMJQ82STW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's also have a quick look at how the city codes look like in the main countries. Let's begin with the US, where we see that partner1 uses the (XX) state code while partner2 doesn't. This may be useful later."
      ]
    },
    {
      "metadata": {
        "id": "7j7oRZET2xhx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### USA"
      ]
    },
    {
      "metadata": {
        "id": "vtGqxDJo2QaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1[unified1['country_code']=='US']['city_name'].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E1IklHds2bVR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2[unified2['country_code']=='US']['city_name'].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UtYdZYls2pTY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### China"
      ]
    },
    {
      "metadata": {
        "id": "jTbcUaTi23Lh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1[unified1['country_code']=='CN']['city_name'].head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N8WTLV7M2qY_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2[unified2['country_code']=='CN']['city_name'].head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGC6m-gC28bQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Thailand"
      ]
    },
    {
      "metadata": {
        "id": "eq4wgFFU2-YN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1[unified1['country_code']=='TH']['city_name'].head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7GPT-qH_3Ai1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2[unified2['country_code']=='TH']['city_name'].head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sikoeEeuyxxf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hotel Address"
      ]
    },
    {
      "metadata": {
        "id": "MHOp2gIm1Onq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We see that on unified1 there are 22 hotels with address \".\", and on unified2 there are 21 hotels with address \" \". We will change those for NaNs"
      ]
    },
    {
      "metadata": {
        "id": "80DAVvPnxWMx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1['hotel_address'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DaXYDxveyeaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2['hotel_address'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WIeMKZ2Qv5d2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean addresses\n",
        "unified1['hotel_address'] = unified1.apply(lambda x: '' if x['hotel_address']=='.' else x['hotel_address'], axis=1)\n",
        "unified2['hotel_address'] = unified2.apply(lambda x: '' if x['hotel_address']==' ' else x['hotel_address'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z1SuW8Gw3Kcj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Star rating"
      ]
    },
    {
      "metadata": {
        "id": "3ZRBwQeO3Pl1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Looks legit. It seems that on average partner1 likes to give more starts than partner2."
      ]
    },
    {
      "metadata": {
        "id": "1vkei-HB2KQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1['star_rating'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xxtNgMMf3N6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2['star_rating'].describe(include='all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0jxuGlGw-t9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Hotel Name"
      ]
    },
    {
      "metadata": {
        "id": "v_Z9OUuJxARr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It would be interesting to see which are the most frequent words. Probably \"Hotel\" or \"Inn\", but is it the same frequency  on both partners? If one of the partners uses the word \"Hotel\" everytime and the other one doesn't it may confuse our string matching model.  \n",
        "\n",
        "Indeed we see that the word \"Hotel\" is the most popular one, but its there on 4368 datapoints on partner 1 while in only 3502 datapoints on partner 2. Maybe we should just simply delete these most common words from the hotel names, for example just \"Hotel\" and \"Inn\" may improve the results. We'll think about that later."
      ]
    },
    {
      "metadata": {
        "id": "2u_yWQM7xIJu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified1['hotel_name'].str.split(expand=True).stack().value_counts().head(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbS9CbM3xgYd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2['hotel_name'].str.split(expand=True).stack().value_counts().head(15)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cRN1BfgoUKo-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Perfect Matches: The easy part"
      ]
    },
    {
      "metadata": {
        "id": "sl_Z6NbaUNwh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If there is a listing with the exact same hotel name, city and country then they are a match. We won't be lucky enough to find that most of our dataset is like that but we can at least split those and reduce the size.\n",
        "\n",
        "We have 3045 out of 10500 (~30%) that are a perfect match. We can take them out from the unified dataset. Note that if would have done the same without caring at the city name we could have splitted about 5300 hotels, meaning there are about 2500 hotels with same name and same country but different city."
      ]
    },
    {
      "metadata": {
        "id": "tJhiAayRI_Re",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp1 = unified1.copy()\n",
        "temp2 = unified2.copy()\n",
        "temp1['hotel_name2'] = temp1['hotel_name'].str.lower()\n",
        "temp1['city_name2'] = temp1['city_name'].str.lower()\n",
        "temp1['country_code2'] = temp1['country_code'].str.lower()\n",
        "temp2['hotel_name2'] = temp2['hotel_name'].str.lower()\n",
        "temp2['city_name2'] = temp2['city_name'].str.lower()\n",
        "temp2['country_code2'] = temp2['country_code'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3zil_emMUg0f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "obvious = pd.merge(temp1, temp2, how='inner', on=['hotel_name2', 'city_name2', 'country_code2'])\n",
        "obvious = obvious[['key_x', 'key_y']]\n",
        "obvious.columns = ['key', 'predicted_key']\n",
        "obvious.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7VctUz60U4Uw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# So this is what we have so far and that we are greatly confident about\n",
        "# 3045 out of 10498 --> 30%\n",
        "matched = matched.append(obvious)\n",
        "matched = matched.reset_index(drop=True)\n",
        "matched.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jt4u90m_ZjyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Drop the perfectly matched hotels from each unified1 and unified2\n",
        "unified1_remain = unified1.merge(matched, left_on=['key'], right_on=['key'], how='left', indicator=True)\n",
        "unified1_remain = unified1_remain[unified1_remain['_merge']=='left_only']\n",
        "unified1_remain.drop(columns=['_merge', 'predicted_key'], inplace=True)\n",
        "print(unified1_remain.shape[0])\n",
        "\n",
        "unified2_remain = unified2.merge(matched, left_on=['key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "unified2_remain = unified2_remain[unified2_remain['_merge']=='left_only']\n",
        "unified2_remain.drop(columns=['_merge', 'key_y', 'predicted_key'], inplace=True)\n",
        "unified2_remain = unified2_remain.rename(columns = {'key_x':'key'})\n",
        "print(unified2_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJFp1yPqzkkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get datapoints inside example that were not yet matched\n",
        "example_remain = example.merge(matched, left_on=['p1.key'], right_on=['key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D6esPanGzmqf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain = example_remain.merge(matched, left_on=['p2.key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gIKADDhROPnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVEEE\n",
        "from google.colab import files\n",
        "caca = matched.to_csv(\"matched_after_obvious.csv\", index=False)\n",
        "files.download('matched_after_obvious.csv')\n",
        "caca = unified1_remain.to_csv(\"unified1_remain_after_obvious.csv\", index=False)\n",
        "files.download('unified1_remain_after_obvious.csv')\n",
        "caca = unified2_remain.to_csv(\"unified2_remain_after_obvious.csv\", index=False)\n",
        "files.download('unified2_remain_after_obvious.csv')\n",
        "caca = example_remain.to_csv(\"example_remain_after_obvious.csv\", index=False)\n",
        "files.download('example_remain_after_obvious.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "snj7yZA-zTNi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Measuring Similarity"
      ]
    },
    {
      "metadata": {
        "id": "92JzswU4VnUp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's think now on how we can do fuzzy string matching since we already took out the perfectly matching hotels. We can define a scoring function and see how it behaves on our labeled data: the examples dataset. We will apply it only on the datapoints that are not a perfect match, otherwise we will see very high scores for perfectly matching names that will corrupt our intuition.  \n",
        "\n",
        "From the total 499 datapoints on example dataset 378 of them are not a perfect match"
      ]
    },
    {
      "metadata": {
        "id": "TvgHaEW0GM8e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nylFMLK4vHrT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's use our 4 fuzzy matching algorithms:\n",
        "- Ratio\n",
        "- Partial Ratio\n",
        "- Token Ratio\n",
        "- Token Set Ratio"
      ]
    },
    {
      "metadata": {
        "id": "bI2XxHR1z3yh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## When there is a match"
      ]
    },
    {
      "metadata": {
        "id": "ZE5i4O0uwDcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hotel Name"
      ]
    },
    {
      "metadata": {
        "id": "xKZ7je8ZGM-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain['name_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_partial_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.partial_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_token_sort_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.token_sort_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_token_set_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.token_set_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YkNNHnUr7CqV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (25,14))\n",
        "plt.subplot(2,2,1)\n",
        "plt.title('Hotel Name: Using the Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['name_ratio'], kde=False);\n",
        "plt.subplot(2,2,2)\n",
        "plt.title('Hotel Name: Using the Partial Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['name_partial_ratio'], kde=False);\n",
        "plt.subplot(2,2,3)\n",
        "plt.title('Hotel Name: Using the Token Sort Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['name_token_sort_ratio'], kde=False);\n",
        "plt.subplot(2,2,4)\n",
        "plt.title('Hotel Name: Using the Token Set Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['name_token_set_ratio'], kde=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ttifKJWSwFV-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hotel Address"
      ]
    },
    {
      "metadata": {
        "id": "AkHhICYPvaNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain['address_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_partial_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.partial_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_token_sort_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.token_sort_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_token_set_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.token_set_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ltr-Rt8SvbRs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (25,14))\n",
        "plt.subplot(2,2,1)\n",
        "plt.title('Hotel Address: Using the Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['address_ratio'], kde=False);\n",
        "plt.subplot(2,2,2)\n",
        "plt.title('Hotel Address: Using the Partial Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['address_partial_ratio'], kde=False);\n",
        "plt.subplot(2,2,3)\n",
        "plt.title('Hotel Address: Using the Token Sort Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['address_token_sort_ratio'], kde=False);\n",
        "plt.subplot(2,2,4)\n",
        "plt.title('Hotel Address: Using the Token Set Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['address_token_set_ratio'], kde=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DlGWKNwzuxi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Hotel City"
      ]
    },
    {
      "metadata": {
        "id": "Q_IJFTDtElfo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain['city_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_partial_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.partial_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_token_sort_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.token_sort_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_token_set_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.token_set_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oujxGEMQEm6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (25,14))\n",
        "plt.subplot(2,2,1)\n",
        "plt.title('Hotel City: Using the Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['city_ratio'], kde=False);\n",
        "plt.subplot(2,2,2)\n",
        "plt.title('Hotel City: Using the Partial Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['city_partial_ratio'], kde=False);\n",
        "plt.subplot(2,2,3)\n",
        "plt.title('Hotel City: Using the Token Sort Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['city_token_sort_ratio'], kde=False);\n",
        "plt.subplot(2,2,4)\n",
        "plt.title('Hotel City: Using the Token Set Ratio' ,color = \"g\")\n",
        "sns.distplot(example_remain['city_token_set_ratio'], kde=False);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7wXeBjoMfoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## When there is no match"
      ]
    },
    {
      "metadata": {
        "id": "Ag6XvtHtMnd8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we will take unified2_remain dataset and erase all the datapoints that belong the partner2 section of the example_remain dataset. That will leave us with a small dataset that is the partner1 section of example_remain and with a big dataset coming from partner2 that has, by design, no matching pairs."
      ]
    },
    {
      "metadata": {
        "id": "gjPTkE4tRsHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unified2_remain.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6prGCsPhVfR4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bad_unified2_remain = unified2_remain.merge(example_remain, left_on=['key'], right_on=['p2.key'], how='left', indicator=True)\n",
        "bad_unified2_remain = bad_unified2_remain[bad_unified2_remain['_merge']=='left_only']\n",
        "bad_unified2_remain = bad_unified2_remain[['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']]\n",
        "bad_unified2_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IRbgANV6WGqH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example1_remain = example_remain[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "example1_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6E_HdE4vWfTp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, for every item on example1_remain we are going to measure the score agianst every element on bad_unified2_remain that is from the same country. Let's define a micro-function for each of the scores and each of the variables (name, city, address) "
      ]
    },
    {
      "metadata": {
        "id": "06LNiXnSWpF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def ratio_getNameScores(row, df):  \n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['name_score'] = country_df.apply(lambda x: fuzz.ratio(row['p1.hotel_name'], x['hotel_name']), axis=1)\n",
        "    ret_a_list = country_df['name_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def ratio_getAddressScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['address_score'] = country_df.apply(lambda x: fuzz.ratio(str(row['p1.hotel_address']), str(x['hotel_address'])), axis=1)\n",
        "    ret_a_list = country_df['address_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def ratio_getCityScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['city_score'] = country_df.apply(lambda x: fuzz.ratio(str(row['p1.city_name']), str(x['city_name'])), axis=1)\n",
        "    ret_a_list = country_df['city_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def partial_getNameScores(row, df):  \n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['name_score'] = country_df.apply(lambda x: fuzz.partial_ratio(row['p1.hotel_name'], x['hotel_name']), axis=1)\n",
        "    ret_a_list = country_df['name_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def partial_getAddressScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['address_score'] = country_df.apply(lambda x: fuzz.partial_ratio(str(row['p1.hotel_address']), str(x['hotel_address'])), axis=1)\n",
        "    ret_a_list = country_df['address_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def partial_getCityScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['city_score'] = country_df.apply(lambda x: fuzz.partial_ratio(str(row['p1.city_name']), str(x['city_name'])), axis=1)\n",
        "    ret_a_list = country_df['city_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def sort_getNameScores(row, df):  \n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['name_score'] = country_df.apply(lambda x: fuzz.token_sort_ratio(row['p1.hotel_name'], x['hotel_name']), axis=1)\n",
        "    ret_a_list = country_df['name_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def sort_getAddressScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['address_score'] = country_df.apply(lambda x: fuzz.token_sort_ratio(str(row['p1.hotel_address']), str(x['hotel_address'])), axis=1)\n",
        "    ret_a_list = country_df['address_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def sort_getCityScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['city_score'] = country_df.apply(lambda x: fuzz.token_sort_ratio(str(row['p1.city_name']), str(x['city_name'])), axis=1)\n",
        "    ret_a_list = country_df['city_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def set_getNameScores(row, df):  \n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['name_score'] = country_df.apply(lambda x: fuzz.token_set_ratio(row['p1.hotel_name'], x['hotel_name']), axis=1)\n",
        "    ret_a_list = country_df['name_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def set_getAddressScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['address_score'] = country_df.apply(lambda x: fuzz.token_set_ratio(str(row['p1.hotel_address']), str(x['hotel_address'])), axis=1)\n",
        "    ret_a_list = country_df['address_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list\n",
        "\n",
        "def set_getCityScores(row, df):\n",
        "  country_df = df[df['country_code']==row['p1.country_code']]\n",
        "  if country_df.shape[0] > 0:\n",
        "    country_df['city_score'] = country_df.apply(lambda x: fuzz.token_set_ratio(str(row['p1.city_name']), str(x['city_name'])), axis=1)\n",
        "    ret_a_list = country_df['city_score'].tolist()\n",
        "  else:\n",
        "    ret_a_list = [np.nan]\n",
        "  return ret_a_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e2eUhm7X0V8O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's run each function. This means that for every datapoint on example1_remain (369) we will run all the similarity scores (4) for all the variables (3) for every datapoint on unified2_remain that is of the same country as tehe query. In total we will get about 180.000 similarity measurements of NOT matching hotels. It takes some time to run..."
      ]
    },
    {
      "metadata": {
        "id": "1wpVA6wlYpQ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(1)\n",
        "example1_remain['ratio_name_score'] = example1_remain.apply(lambda x: ratio_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(2)\n",
        "example1_remain['ratio_address_score'] = example1_remain.apply(lambda x: ratio_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(3)\n",
        "example1_remain['ratio_city_score'] = example1_remain.apply(lambda x: ratio_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(4)\n",
        "example1_remain['partial_name_score'] = example1_remain.apply(lambda x: partial_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(5)\n",
        "example1_remain['partial_address_score'] = example1_remain.apply(lambda x: partial_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(6)\n",
        "example1_remain['partial_city_score'] = example1_remain.apply(lambda x: partial_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(7)\n",
        "example1_remain['sort_name_score'] = example1_remain.apply(lambda x: sort_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(8)\n",
        "example1_remain['sort_address_score'] = example1_remain.apply(lambda x: sort_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(9)\n",
        "example1_remain['sort_city_score'] = example1_remain.apply(lambda x: sort_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(10)\n",
        "example1_remain['set_name_score'] = example1_remain.apply(lambda x: set_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(11)\n",
        "example1_remain['set_address_score'] = example1_remain.apply(lambda x: set_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(12)\n",
        "example1_remain['set_city_score'] = example1_remain.apply(lambda x: set_getCityScores(x, bad_unified2_remain), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VojWabkv1H4T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Match vs No-Match"
      ]
    },
    {
      "metadata": {
        "id": "RMETVdAR1UHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have the scores of the matching datapoints and we also have the score of the not-matching variables. Let's say that for every score type (ratio, partial, sort, set) we sum the scores of the features (name, city, address). Let's say we do a normalized weighted sum. Let's write a function to do that and that returns us some nice graphs that depend on 3 parameters: b, k, p  \n",
        "\n",
        "**Score = b(name_score) + k(address_score) + p(city_score)**\n",
        "\n",
        "Let's play with the parameters to get some intuition and great graphs for the presentation"
      ]
    },
    {
      "metadata": {
        "id": "PmsAyJSRYu0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b = 1\n",
        "k = 1\n",
        "p = 1\n",
        "\n",
        "factor = 3/(b+k+p)\n",
        "b = b*factor\n",
        "k = k*factor\n",
        "p = p*factor\n",
        "\n",
        "from scipy.stats import norm\n",
        "plt.figure(figsize = (25,14))\n",
        "\n",
        "# Ratio \n",
        "plt.subplot(2,2,1)\n",
        "\n",
        "scores1a = example1_remain['ratio_name_score']\n",
        "scores1a = [item for items in scores1a for item in items]\n",
        "scores1a = [x for x in scores1a if ~np.isnan(x)]\n",
        "scores1am = [b*i for i in scores1a]\n",
        "\n",
        "scores2a = example1_remain['ratio_address_score']\n",
        "scores2a = [item for items in scores2a for item in items]\n",
        "scores2a = [x for x in scores2a if ~np.isnan(x)]\n",
        "scores2am = [k*i for i in scores2a]\n",
        "\n",
        "scores3a = example1_remain['ratio_city_score']\n",
        "scores3a = [item for items in scores3a for item in items]\n",
        "scores3a = [x for x in scores3a if ~np.isnan(x)]\n",
        "scores3am = [p*i for i in scores3a]\n",
        "\n",
        "score_suma = [x+y+z for x, y, z in zip(scores1am, scores2am, scores3am)]\n",
        "turth_suma = b*example_remain['name_ratio'] + k*example_remain['address_ratio'] + p*example_remain['city_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1am, scores2am, scores3am)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_ratio'], k*example_remain['address_ratio'], p*example_remain['city_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Ratio' ,color = \"g\")\n",
        "plt.hist(score_suma, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_suma, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Partial Ratio\n",
        "plt.subplot(2,2,2)\n",
        "\n",
        "scores1b = example1_remain['partial_name_score']\n",
        "scores1b = [item for items in scores1b for item in items]\n",
        "scores1b = [x for x in scores1b if ~np.isnan(x)]\n",
        "scores1bm = [b*i for i in scores1b]\n",
        "\n",
        "scores2b = example1_remain['partial_address_score']\n",
        "scores2b = [item for items in scores2b for item in items]\n",
        "scores2b = [x for x in scores2b if ~np.isnan(x)]\n",
        "scores2bm = [k*i for i in scores2b]\n",
        "\n",
        "scores3b = example1_remain['partial_city_score']\n",
        "scores3b = [item for items in scores3b for item in items]\n",
        "scores3b = [x for x in scores3b if ~np.isnan(x)]\n",
        "scores3bm = [p*i for i in scores3b]\n",
        "\n",
        "score_sumb = [x+y+z for x, y, z in zip(scores1bm, scores2bm, scores3bm)]\n",
        "turth_sumb = b*example_remain['name_partial_ratio'] + k*example_remain['address_partial_ratio'] + p*example_remain['city_partial_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1bm, scores2bm, scores3bm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_partial_ratio'], k*example_remain['address_partial_ratio'], p*example_remain['city_partial_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Partial Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumb, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_sumb, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Token Sort Ratio\n",
        "plt.subplot(2,2,3)\n",
        "\n",
        "scores1c = example1_remain['sort_name_score']\n",
        "scores1c = [item for items in scores1c for item in items]\n",
        "scores1c = [x for x in scores1c if ~np.isnan(x)]\n",
        "scores1cm = [b*i for i in scores1c]\n",
        "\n",
        "scores2c = example1_remain['sort_address_score']\n",
        "scores2c = [item for items in scores2c for item in items]\n",
        "scores2c = [x for x in scores2c if ~np.isnan(x)]\n",
        "scores2cm = [k*i for i in scores2c]\n",
        "\n",
        "scores3c = example1_remain['sort_city_score']\n",
        "scores3c = [item for items in scores3c for item in items]\n",
        "scores3c = [x for x in scores3c if ~np.isnan(x)]\n",
        "scores3cm = [p*i for i in scores3c]\n",
        "\n",
        "score_sumc = [x+y+z for x, y, z in zip(scores1cm, scores2cm, scores3cm)]\n",
        "turth_sumc = b*example_remain['name_token_sort_ratio'] + k*example_remain['address_token_sort_ratio'] + p*example_remain['city_token_sort_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1cm, scores2cm, scores3cm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_token_sort_ratio'], k*example_remain['address_token_sort_ratio'], p*example_remain['city_token_sort_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Token Sort Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumc, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_sumc, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Token Set Ratio\n",
        "plt.subplot(2,2,4)\n",
        "\n",
        "scores1d = example1_remain['set_name_score']\n",
        "scores1d = [item for items in scores1d for item in items]\n",
        "scores1d = [x for x in scores1d if ~np.isnan(x)]\n",
        "scores1dm = [b*i for i in scores1d]\n",
        "\n",
        "scores2d = example1_remain['set_address_score']\n",
        "scores2d = [item for items in scores2d for item in items]\n",
        "scores2d = [x for x in scores2d if ~np.isnan(x)]\n",
        "scores2dm = [k*i for i in scores2d]\n",
        "\n",
        "scores3d = example1_remain['set_city_score']\n",
        "scores3d = [item for items in scores3d for item in items]\n",
        "scores3d = [x for x in scores3d if ~np.isnan(x)]\n",
        "scores3dm = [p*i for i in scores3d]\n",
        "\n",
        "score_sumd = [x+y+z for x, y, z in zip(scores1dm, scores2dm, scores3dm)];\n",
        "turth_sumd = b*example_remain['name_token_set_ratio'] + k*example_remain['address_token_set_ratio'] + p*example_remain['city_token_set_ratio'];\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1dm, scores2dm, scores3dm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_token_set_ratio'], k*example_remain['address_token_set_ratio'], p*example_remain['city_token_set_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Token Set Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumd, normed=True, alpha = 0.5, bins=np.linspace(0,300,30));\n",
        "plt.hist(turth_sumd, normed=True, alpha = 0.5, bins=np.linspace(0,300,30));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j3lYIQz1HJOZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Filter out by optimal score separation"
      ]
    },
    {
      "metadata": {
        "id": "yRLIyxxiHMVj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We found the optimal parameters using optimization of the following objetive function. When using the parameters (b,k,p) = (1,0.35,0.1) under the token_set_ratio we can feel sure to say that if the score is above 280 then it's a match."
      ]
    },
    {
      "metadata": {
        "id": "FG9xm9vitZUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def objective(x, score1fake, score2fake, score3fake, score1true, score2true, score3true):\n",
        "  \n",
        "  b = x[0]\n",
        "  k = x[1]\n",
        "  p = x[2]\n",
        "  \n",
        "  factor = 3/(b+k+p)\n",
        "  b = b*factor\n",
        "  k = k*factor\n",
        "  p = p*factor\n",
        "  \n",
        "  score1fake = [b*i for i in score1fake]\n",
        "  score2fake = [k*i for i in score2fake]\n",
        "  score3fake = [p*i for i in score3fake]\n",
        "\n",
        "  score1true = [b*i for i in score1true]\n",
        "  score2true = [k*i for i in score2true]\n",
        "  score3true = [p*i for i in score3true]\n",
        "  \n",
        "  scoreFake = [x+y+z for x, y, z in zip(score1fake, score2fake, score3fake)]\n",
        "  scoreTrue = [x+y+z for x, y, z in zip(score1true, score2true, score3true)]\n",
        "  \n",
        "  maxFake = max(scoreFake)  \n",
        "  numOfGreater = sum(i > maxFake+10 for i in scoreTrue)\n",
        "  \n",
        "  score = numOfGreater\n",
        "  \n",
        "  return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tXDMPrJtH0K3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getScore(row, df):\n",
        "    \n",
        "  # Calculate score\n",
        "  df['scores1d'] = df.apply(lambda x: fuzz.token_set_ratio(row['hotel_name'], x['hotel_name']), axis=1)\n",
        "  df['scores2d'] = df.apply(lambda x: fuzz.token_set_ratio(str(row['hotel_address']), str(x['hotel_address'])), axis=1)\n",
        "  df['scores3d'] = df.apply(lambda x: fuzz.token_set_ratio(str(row['city_name']), str(x['city_name'])), axis=1)\n",
        "  df['tot_score'] = 2.069*df['scores1d'] + 0.72*df['scores2d'] + 0.2*df['scores3d']\n",
        "  df['match'] = df.apply(lambda x: 1 if x['tot_score']>280 else 0, axis=1)\n",
        "  \n",
        "  # Sum the amount of matches\n",
        "  suma = df['match'].sum()\n",
        "  \n",
        "  if suma!=1:\n",
        "    pred_key = 'bla'\n",
        "  else:\n",
        "    pred_key = df[df['match']==1]['key'].values\n",
        "    pred_key = pred_key[0]\n",
        "\n",
        "  return pred_key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qUxKTSizH0K4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def runModule(dataframe1, dataframe2, countries=None):\n",
        "\n",
        "  if countries is None:\n",
        "    # Get list of available countries on unified dataframe from partner1\n",
        "    countries = dataframe1['country_code'].unique()\n",
        "\n",
        "  # Initialize output dataframe\n",
        "  outDf = pd.DataFrame(columns = ['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code', 'predicted_key'])\n",
        "    \n",
        "  # Run for each country\n",
        "  for cou in countries:\n",
        "\n",
        "    print(cou)\n",
        "\n",
        "    # Filter dataframes by country    \n",
        "    df1 = dataframe1[dataframe1['country_code']==cou]\n",
        "    df2 = dataframe2[dataframe2['country_code']==cou]\n",
        "    \n",
        "    if df2.shape[0]<1:\n",
        "      df1['predicted_key'] = 'bla'\n",
        "    else:\n",
        "      # Call the Scoring function to get predicted_key, score and second_score \n",
        "      df1['predicted_key'] = df1.apply(lambda x: getScore(x, df2), axis=1)\n",
        "\n",
        "    # Append to results dataframe\n",
        "    outDf = outDf.append(df1)\n",
        "\n",
        "  return outDf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pu6F1BClH0K5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "run = 1\n",
        "\n",
        "if run == 1:\n",
        "  ttt = runModule(unified1_remain, unified2_remain)\n",
        "else:\n",
        "  from google.colab import files\n",
        "  import pandas as pd\n",
        "  import io\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  ttt = pd.read_csv(io.StringIO(uploaded['A_ttt.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QUwH9xpzBBch",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVEEE\n",
        "from google.colab import files\n",
        "caca = ttt.to_csv(\"ttt.csv\", index=False)\n",
        "files.download('ttt.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoxstZCPZ44D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ttt.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpjM_lirHlkc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's see how many did we match and how many we didn't\n",
        "print(ttt[ttt['predicted_key']!='bla'].shape[0])\n",
        "print(ttt[ttt['predicted_key']=='bla'].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxWWo4VJM_ra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cut the datapoints that where matched and check for duplicates\n",
        "matched_by_ratio = ttt[ttt['predicted_key']!='bla']\n",
        "print(matched_by_ratio[matched_by_ratio.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched_by_ratio[matched_by_ratio.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIwXu98YZCK0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#matched_by_ratio = matched_by_ratio[matched_by_ratio.duplicated(subset=['predicted_key'], keep=False)]\n",
        "matched_by_ratio_pais = matched_by_ratio[['key', 'predicted_key']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9oDURbtnNdYx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add the key pairs to the matched dataframe\n",
        "matched = matched.append(matched_by_ratio_pais)\n",
        "matched.reset_index(drop=True, inplace=True)\n",
        "matched.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6CZzkAGaIDK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(matched[matched.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched[matched.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VrLfalutUb17",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Drop the matched hotels from each unified1 and unified2\n",
        "unified1_remain = unified1.merge(matched, left_on=['key'], right_on=['key'], how='left', indicator=True)\n",
        "unified1_remain = unified1_remain[unified1_remain['_merge']=='left_only']\n",
        "unified1_remain.drop(columns=['_merge', 'predicted_key'], inplace=True)\n",
        "print(unified1_remain.shape[0])\n",
        "\n",
        "unified2_remain = unified2.merge(matched, left_on=['key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "unified2_remain = unified2_remain[unified2_remain['_merge']=='left_only']\n",
        "unified2_remain.drop(columns=['_merge', 'key_y', 'predicted_key'], inplace=True)\n",
        "unified2_remain = unified2_remain.rename(columns = {'key_x':'key'})\n",
        "print(unified2_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JXV7NOSkUb19",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get datapoints inside example that were not yet matched\n",
        "example_remain = example.merge(matched, left_on=['p1.key'], right_on=['key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "g12Ez1iXUb2D",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain = example_remain.merge(matched, left_on=['p2.key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YwE3Yyi0Ub2H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVEEE\n",
        "from google.colab import files\n",
        "caca = matched.to_csv(\"matched_after_score_th.csv\", index=False)\n",
        "files.download('matched_after_score_th.csv')\n",
        "caca = unified1_remain.to_csv(\"unified1_remain_after_score_th.csv\", index=False)\n",
        "files.download('unified1_remain_after_score_th.csv')\n",
        "caca = unified2_remain.to_csv(\"unified2_remain_after_score_th.csv\", index=False)\n",
        "files.download('unified2_remain_after_score_th.csv')\n",
        "caca = example_remain.to_csv(\"example_remain_after_score_th.csv\", index=False)\n",
        "files.download('example_remain_after_score_th.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDxc-mEZPpiJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As before, calculate the section of the unified2_remain that has is not labeled\n",
        "bad_unified2_remain = unified2_remain.merge(example_remain, left_on=['key'], right_on=['p2.key'], how='left', indicator=True)\n",
        "bad_unified2_remain = bad_unified2_remain[bad_unified2_remain['_merge']=='left_only']\n",
        "bad_unified2_remain = bad_unified2_remain[['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']]\n",
        "print(bad_unified2_remain.shape[0])\n",
        "\n",
        "# Calculate the partner1 section of the labeled data\n",
        "example1_remain = example_remain[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "print(example1_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Ht-nmSEif3-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# A 12 dimensional space"
      ]
    },
    {
      "metadata": {
        "id": "OdGyr8X_3Suv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have a lot of data. We have about 33.250 datapoints that we know for sure are not a match and we also have 137 datapoints that we know are a match. For each datapoint we have 12 features! The score for the name, address and city similarity using 4 different methods. How about we use those features and the big amount of data we have to build a Decision Tree classifier that will be more efficient on splitting the space than our (b, k, p) partition."
      ]
    },
    {
      "metadata": {
        "id": "otiF9gSpInyR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Repeat scoring process for the remaining \"labeled\" data\n",
        "example_remain['name_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_partial_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.partial_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_token_sort_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.token_sort_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "example_remain['name_token_set_ratio'] = example_remain[['p1.hotel_name', 'p2.hotel_name']].apply(lambda x: fuzz.token_set_ratio(x['p1.hotel_name'], x['p2.hotel_name']), axis=1)\n",
        "\n",
        "example_remain['address_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_partial_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.partial_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_token_sort_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.token_sort_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "example_remain['address_token_set_ratio'] = example_remain[['p1.hotel_address', 'p2.hotel_address']].apply(lambda x: fuzz.token_set_ratio(str(x['p1.hotel_address']), str(x['p2.hotel_address'])), axis=1)\n",
        "\n",
        "example_remain['city_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_partial_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.partial_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_token_sort_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.token_sort_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)\n",
        "example_remain['city_token_set_ratio'] = example_remain[['p1.city_name', 'p2.city_name']].apply(lambda x: fuzz.token_set_ratio(str(x['p1.city_name']), str(x['p2.city_name'])), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VqSVdG8kI5VZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Repeat the scoring process for the labeled data from partner1 against the wrong matches of unified2_remain\n",
        "print(1)\n",
        "example1_remain['ratio_name_score'] = example1_remain.apply(lambda x: ratio_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(2)\n",
        "example1_remain['ratio_address_score'] = example1_remain.apply(lambda x: ratio_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(3)\n",
        "example1_remain['ratio_city_score'] = example1_remain.apply(lambda x: ratio_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(4)\n",
        "example1_remain['partial_name_score'] = example1_remain.apply(lambda x: partial_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(5)\n",
        "example1_remain['partial_address_score'] = example1_remain.apply(lambda x: partial_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(6)\n",
        "example1_remain['partial_city_score'] = example1_remain.apply(lambda x: partial_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(7)\n",
        "example1_remain['sort_name_score'] = example1_remain.apply(lambda x: sort_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(8)\n",
        "example1_remain['sort_address_score'] = example1_remain.apply(lambda x: sort_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(9)\n",
        "example1_remain['sort_city_score'] = example1_remain.apply(lambda x: sort_getCityScores(x, bad_unified2_remain), axis=1)\n",
        "print(10)\n",
        "example1_remain['set_name_score'] = example1_remain.apply(lambda x: set_getNameScores(x, bad_unified2_remain), axis=1)\n",
        "print(11)\n",
        "example1_remain['set_address_score'] = example1_remain.apply(lambda x: set_getAddressScores(x, bad_unified2_remain), axis=1)\n",
        "print(12)\n",
        "example1_remain['set_city_score'] = example1_remain.apply(lambda x: set_getCityScores(x, bad_unified2_remain), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JLr_PQx6JDf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recalculate the scores that we are going to use for the classifier\n",
        "b = 1\n",
        "k = 1\n",
        "p = 1\n",
        "\n",
        "factor = 3/(b+k+p)\n",
        "b = b*factor\n",
        "k = k*factor\n",
        "p = p*factor\n",
        "\n",
        "from scipy.stats import norm\n",
        "plt.figure(figsize = (25,14))\n",
        "\n",
        "# Ratio \n",
        "plt.subplot(2,2,1)\n",
        "\n",
        "scores1a = example1_remain['ratio_name_score']\n",
        "scores1a = [item for items in scores1a for item in items]\n",
        "scores1a = [x for x in scores1a if ~np.isnan(x)]\n",
        "scores1am = [b*i for i in scores1a]\n",
        "\n",
        "scores2a = example1_remain['ratio_address_score']\n",
        "scores2a = [item for items in scores2a for item in items]\n",
        "scores2a = [x for x in scores2a if ~np.isnan(x)]\n",
        "scores2am = [k*i for i in scores2a]\n",
        "\n",
        "scores3a = example1_remain['ratio_city_score']\n",
        "scores3a = [item for items in scores3a for item in items]\n",
        "scores3a = [x for x in scores3a if ~np.isnan(x)]\n",
        "scores3am = [p*i for i in scores3a]\n",
        "\n",
        "score_suma = [x+y+z for x, y, z in zip(scores1am, scores2am, scores3am)]\n",
        "turth_suma = b*example_remain['name_ratio'] + k*example_remain['address_ratio'] + p*example_remain['city_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1am, scores2am, scores3am)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_ratio'], k*example_remain['address_ratio'], p*example_remain['city_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Ratio' ,color = \"g\")\n",
        "plt.hist(score_suma, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_suma, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Partial Ratio\n",
        "plt.subplot(2,2,2)\n",
        "\n",
        "scores1b = example1_remain['partial_name_score']\n",
        "scores1b = [item for items in scores1b for item in items]\n",
        "scores1b = [x for x in scores1b if ~np.isnan(x)]\n",
        "scores1bm = [b*i for i in scores1b]\n",
        "\n",
        "scores2b = example1_remain['partial_address_score']\n",
        "scores2b = [item for items in scores2b for item in items]\n",
        "scores2b = [x for x in scores2b if ~np.isnan(x)]\n",
        "scores2bm = [k*i for i in scores2b]\n",
        "\n",
        "scores3b = example1_remain['partial_city_score']\n",
        "scores3b = [item for items in scores3b for item in items]\n",
        "scores3b = [x for x in scores3b if ~np.isnan(x)]\n",
        "scores3bm = [p*i for i in scores3b]\n",
        "\n",
        "score_sumb = [x+y+z for x, y, z in zip(scores1bm, scores2bm, scores3bm)]\n",
        "turth_sumb = b*example_remain['name_partial_ratio'] + k*example_remain['address_partial_ratio'] + p*example_remain['city_partial_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1bm, scores2bm, scores3bm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_partial_ratio'], k*example_remain['address_partial_ratio'], p*example_remain['city_partial_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Partial Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumb, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_sumb, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Token Sort Ratio\n",
        "plt.subplot(2,2,3)\n",
        "\n",
        "scores1c = example1_remain['sort_name_score']\n",
        "scores1c = [item for items in scores1c for item in items]\n",
        "scores1c = [x for x in scores1c if ~np.isnan(x)]\n",
        "scores1cm = [b*i for i in scores1c]\n",
        "\n",
        "scores2c = example1_remain['sort_address_score']\n",
        "scores2c = [item for items in scores2c for item in items]\n",
        "scores2c = [x for x in scores2c if ~np.isnan(x)]\n",
        "scores2cm = [k*i for i in scores2c]\n",
        "\n",
        "scores3c = example1_remain['sort_city_score']\n",
        "scores3c = [item for items in scores3c for item in items]\n",
        "scores3c = [x for x in scores3c if ~np.isnan(x)]\n",
        "scores3cm = [p*i for i in scores3c]\n",
        "\n",
        "score_sumc = [x+y+z for x, y, z in zip(scores1cm, scores2cm, scores3cm)]\n",
        "turth_sumc = b*example_remain['name_token_sort_ratio'] + k*example_remain['address_token_sort_ratio'] + p*example_remain['city_token_sort_ratio']\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1cm, scores2cm, scores3cm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_token_sort_ratio'], k*example_remain['address_token_sort_ratio'], p*example_remain['city_token_sort_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Token Sort Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumc, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "plt.hist(turth_sumc, normed=True, alpha = 0.5, bins=np.linspace(0,300,30))\n",
        "\n",
        "# Token Set Ratio\n",
        "plt.subplot(2,2,4)\n",
        "\n",
        "scores1d = example1_remain['set_name_score']\n",
        "scores1d = [item for items in scores1d for item in items]\n",
        "scores1d = [x for x in scores1d if ~np.isnan(x)]\n",
        "scores1dm = [b*i for i in scores1d]\n",
        "\n",
        "scores2d = example1_remain['set_address_score']\n",
        "scores2d = [item for items in scores2d for item in items]\n",
        "scores2d = [x for x in scores2d if ~np.isnan(x)]\n",
        "scores2dm = [k*i for i in scores2d]\n",
        "\n",
        "scores3d = example1_remain['set_city_score']\n",
        "scores3d = [item for items in scores3d for item in items]\n",
        "scores3d = [x for x in scores3d if ~np.isnan(x)]\n",
        "scores3dm = [p*i for i in scores3d]\n",
        "\n",
        "score_sumd = [x+y+z for x, y, z in zip(scores1dm, scores2dm, scores3dm)];\n",
        "turth_sumd = b*example_remain['name_token_set_ratio'] + k*example_remain['address_token_set_ratio'] + p*example_remain['city_token_set_ratio'];\n",
        "\n",
        "#####\n",
        "#score_suma = [max(x,y,z) for x,y,z in zip(scores1dm, scores2dm, scores3dm)]\n",
        "#turth_suma = [max(x,y,z) for x,y,z in zip(b*example_remain['name_token_set_ratio'], k*example_remain['address_token_set_ratio'], p*example_remain['city_token_set_ratio'])]\n",
        "#####\n",
        "\n",
        "plt.title('Hotel Name + Hotel Address + Hotel City: Using the Token Set Ratio' ,color = \"g\")\n",
        "plt.hist(score_sumd, normed=True, alpha = 0.5, bins=np.linspace(0,300,30));\n",
        "plt.hist(turth_sumd, normed=True, alpha = 0.5, bins=np.linspace(0,300,30));"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jcwssPKqe6bR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build the NO-match dataframe\n",
        "d_fake = {'scores1a': scores1a, 'scores2a': scores2a, 'scores3a': scores3a, \n",
        "          'scores1b': scores1b, 'scores2b': scores2b, 'scores3b': scores3b, \n",
        "          'scores1c': scores1c, 'scores2c': scores2c, 'scores3c': scores3c, \n",
        "          'scores1d': scores1d, 'scores2d': scores2d, 'scores3d': scores3d}\n",
        "df_fake = pd.DataFrame(data=d_fake)\n",
        "df_fake['label']=0\n",
        "\n",
        "# Build the YES-match dataframe\n",
        "d_true = {'scores1a': example_remain['name_ratio'], 'scores2a': example_remain['address_ratio'],\n",
        "          'scores3a': example_remain['city_ratio'], 'scores1b': example_remain['name_partial_ratio'],\n",
        "          'scores2b': example_remain['address_partial_ratio'], 'scores3b': example_remain['city_partial_ratio'],\n",
        "          'scores1c': example_remain['name_token_sort_ratio'], 'scores2c': example_remain['address_token_sort_ratio'],\n",
        "          'scores3c': example_remain['city_token_sort_ratio'], 'scores1d': example_remain['name_token_set_ratio'],\n",
        "          'scores2d': example_remain['address_token_set_ratio'], 'scores3d': example_remain['city_token_set_ratio']}\n",
        "df_true = pd.DataFrame(data=d_true)\n",
        "df_true['label']=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWeEAno-iiQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Merge the dataframes, reset_index and take a look\n",
        "df = df_true.append(df_fake)\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AYW478iBzRx8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SAVEEEEEE\n",
        "from google.colab import files\n",
        "caca = df.to_csv(\"A_12dim.csv\", index=False)\n",
        "files.download('A_12dim.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "945g6QT4j9KC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = ['scores1a', 'scores1b', 'scores1c', 'scores1d', 'scores2a', 'scores2b', 'scores2c', 'scores2d', 'scores3a', 'scores3b', 'scores3c', 'scores3d', 'label']\n",
        "#features = ['scores1a', 'scores1c', 'scores1d', 'scores2c', 'scores2d', 'label']\n",
        "#features = ['scores1a', 'scores1d', 'scores2c', 'scores2d', 'scores3b', 'label']\n",
        "#features = ['scores3b', 'scores3d', 'label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nw8abi0hWSiD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Name Ratio  \n",
        "Name Set  \n",
        "Name Sort  \n",
        "Address Set  \n",
        "Address Sort  "
      ]
    },
    {
      "metadata": {
        "id": "-Fdiw_uJJF3j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ]
    },
    {
      "metadata": {
        "id": "DLCLf3svJHio",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train - Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df[features], test_size=0.3)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Features and Label split\n",
        "X_train = df_train.drop(columns=['label'])\n",
        "Y_train = df_train['label']\n",
        "X_test = df_test.drop(columns=['label'])\n",
        "Y_test = df_test['label']\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "model = XGBClassifier(n_estimators=400, objective = 'binary:logistic', scale_pos_weight=1)\n",
        "model = model.fit(X_train, Y_train)\n",
        "Y_pred = model.predict(X_test)\n",
        "Y_proba = model.predict_proba(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf = confusion_matrix(Y_test, Y_pred)\n",
        "print(conf)\n",
        "\n",
        "a = conf[0][0]\n",
        "b = conf[0][1]\n",
        "c = conf[1][0]\n",
        "d = conf[1][1]\n",
        "\n",
        "acc = 1- b*c/((c+d)*(c+d))\n",
        "cov = d/(c+d) - (b/(c+d))*(d/(c+d)) + (b/(c+d))*(c/(c+d))\n",
        "\n",
        "print(acc)\n",
        "print(cov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XzDWW4vZfSHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "metadata": {
        "id": "5ffzc8lofV7y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Train - Test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df[features], test_size=0.02)\n",
        "df_train.reset_index(drop=True, inplace=True)\n",
        "df_test.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Features and Label split\n",
        "X_train = df_train.drop(columns=['label'])\n",
        "Y_train = df_train['label']\n",
        "X_test = df_test.drop(columns=['label'])\n",
        "Y_test = df_test['label']\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn import ensemble\n",
        "model = linear_model.LogisticRegression(class_weight = {0:1,1:5}).fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = model.predict(X_test)\n",
        "Y_prob = model.predict_proba(X_test)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "conf = confusion_matrix(Y_test, Y_pred)\n",
        "print(conf)\n",
        "\n",
        "a = conf[0][0]\n",
        "b = conf[0][1]\n",
        "c = conf[1][0]\n",
        "d = conf[1][1]\n",
        "\n",
        "acc = 1- b*c/((c+d)*(c+d))\n",
        "cov = d/(c+d) - (b/(c+d))*(d/(c+d)) + (b/(c+d))*(c/(c+d))\n",
        "\n",
        "print(acc)\n",
        "print(cov)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rj91dJBD7E90",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applying the model"
      ]
    },
    {
      "metadata": {
        "id": "37LLLJlm7u0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have unified1_remain and unified2_remain, each with 2900 datapoints that include 137 datapoints that belong to the examples dataset."
      ]
    },
    {
      "metadata": {
        "id": "gZRruM0PFLTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Making a matching key function \n",
        "\n",
        "What we should do now is make a function that for any given datapoint from unified1_remain it calculates the 12 different scores that we have seen for every single point on unified2_remain that is from the same country as the query point. Then those 12 scores should go trough the logostic regression model and:\n",
        "- In case there are no matches the datapoint has no match\n",
        "- In case there is a single match the datapoint has a match\n",
        "- In case there are more than 2 matches the datapoint has NO match\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Uzel6FJB3sro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getMatchingKey(row, dfi, features):\n",
        "  \n",
        "  df = dfi[dfi['country_code']==row['country_code']]\n",
        "  \n",
        "  # Calculate score for all 12 features \n",
        "  df['scores1a'] = df.apply(lambda x: fuzz.ratio(x['hotel_name'], row['hotel_name']), axis=1)\n",
        "  df['scores2a'] = df.apply(lambda x: fuzz.ratio(str(x['hotel_address']), str(row['hotel_address'])), axis=1)\n",
        "  df['scores3a'] = df.apply(lambda x: fuzz.ratio(str(x['city_name']), str(row['city_name'])), axis=1)\n",
        "  df['scores1b'] = df.apply(lambda x: fuzz.partial_ratio(x['hotel_name'], row['hotel_name']), axis=1)\n",
        "  df['scores2b'] = df.apply(lambda x: fuzz.partial_ratio(str(x['hotel_address']), str(row['hotel_address'])), axis=1)\n",
        "  df['scores3b'] = df.apply(lambda x: fuzz.partial_ratio(str(x['city_name']), str(row['city_name'])), axis=1)\n",
        "  df['scores1c'] = df.apply(lambda x: fuzz.token_sort_ratio(x['hotel_name'], row['hotel_name']), axis=1)\n",
        "  df['scores2c'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['hotel_address']), str(row['hotel_address'])), axis=1)\n",
        "  df['scores3c'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['city_name']), str(row['city_name'])), axis=1)\n",
        "  df['scores1d'] = df.apply(lambda x: fuzz.token_set_ratio(x['hotel_name'], row['hotel_name']), axis=1)\n",
        "  df['scores2d'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['hotel_address']), str(row['hotel_address'])), axis=1)\n",
        "  df['scores3d'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['city_name']), str(row['city_name'])), axis=1)\n",
        "  \n",
        "  # Call Model\n",
        "  suma = model.predict(df[features]).sum()\n",
        "  if suma != 1:\n",
        "    pred_key = 'bla'\n",
        "  else:  \n",
        "    df['prediction'] = model.predict(df[features])\n",
        "    pred_key = df[df['prediction']==1]['key'].values\n",
        "    pred_key = pred_key[0]\n",
        "  \n",
        "  return pred_key"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VDDkqFS7LzsF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "caca1 = unified1_remain.copy()\n",
        "caca2 = unified2_remain.copy()\n",
        "caca1 = caca1\n",
        "features = ['scores1a', 'scores1b', 'scores1c', 'scores1d', 'scores2a', 'scores2b', 'scores2c', 'scores2d', 'scores3a', 'scores3b', 'scores3c', 'scores3d']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jUnD0ujNTRn5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "caca1['predicted_key'] = caca1.apply(lambda x: getMatchingKey(x, caca2, features), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FlyubZEbEOFi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SAVEEEEEE\n",
        "from google.colab import files\n",
        "hrgtf = caca1.to_csv(\"cacaaa.csv\", index=False)\n",
        "files.download('cacaaa.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pYqIf77QYroY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOADDDD\n",
        "  from google.colab import files\n",
        "  import pandas as pd\n",
        "  import io\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  matched = pd.read_csv(io.StringIO(uploaded['matched_after_score_th.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2lvTvCknZSqo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOADDDD\n",
        "  from google.colab import files\n",
        "  import pandas as pd\n",
        "  import io\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  caca1 = pd.read_csv(io.StringIO(uploaded['cacaaa.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gevz-YXF2Mmr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Let's see how many did we match and how many we didn't\n",
        "print(caca1[caca1['predicted_key']!='bla'].shape[0])\n",
        "print(caca1[caca1['predicted_key']=='bla'].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TmdI5zuK2Mmu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Cut the datapoints that where matched and check for duplicates\n",
        "matched_by_logistic = caca1[caca1['predicted_key']!='bla']\n",
        "print(matched_by_logistic[matched_by_logistic.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched_by_logistic[matched_by_logistic.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KVSSLXeYZnkK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Delete duplicates\n",
        "matched_by_logistic = matched_by_logistic.drop_duplicates(subset='predicted_key', keep=False)\n",
        "print(matched_by_logistic[matched_by_logistic.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched_by_logistic[matched_by_logistic.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q-NiFcwC2Mmy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#matched_by_ratio = matched_by_ratio[matched_by_ratio.duplicated(subset=['predicted_key'], keep=False)]\n",
        "matched_by_logistic_pairs = matched_by_logistic[['key', 'predicted_key']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6yK3Xfgu2Mm1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Add the key pairs to the matched dataframe\n",
        "matched = matched.append(matched_by_logistic_pairs)\n",
        "matched.reset_index(drop=True, inplace=True)\n",
        "matched.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wSwyILJe2Mm4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(matched[matched.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched[matched.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EEHdiJTs2Mm9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Drop the matched hotels from each unified1 and unified2\n",
        "unified1_remain = unified1.merge(matched, left_on=['key'], right_on=['key'], how='left', indicator=True)\n",
        "unified1_remain = unified1_remain[unified1_remain['_merge']=='left_only']\n",
        "unified1_remain.drop(columns=['_merge', 'predicted_key'], inplace=True)\n",
        "print(unified1_remain.shape[0])\n",
        "\n",
        "unified2_remain = unified2.merge(matched, left_on=['key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "unified2_remain = unified2_remain[unified2_remain['_merge']=='left_only']\n",
        "unified2_remain.drop(columns=['_merge', 'key_y', 'predicted_key'], inplace=True)\n",
        "unified2_remain = unified2_remain.rename(columns = {'key_x':'key'})\n",
        "print(unified2_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MNwKRqd32MnD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get datapoints inside example that were not yet matched\n",
        "example_remain = example.merge(matched, left_on=['p1.key'], right_on=['key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7SfIPVY-2MnG",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain = example_remain.merge(matched, left_on=['p2.key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ded12ibv2MnJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#SAVEEE\n",
        "from google.colab import files\n",
        "caca = matched.to_csv(\"matched_after_logistic.csv\", index=False)\n",
        "files.download('matched_after_logistic.csv')\n",
        "caca = unified1_remain.to_csv(\"unified1_remain_after_logistic.csv\", index=False)\n",
        "files.download('unified1_remain_after_logistic.csv')\n",
        "caca = unified2_remain.to_csv(\"unified2_remain_after_logistic.csv\", index=False)\n",
        "files.download('unified2_remain_after_logistic.csv')\n",
        "caca = example_remain.to_csv(\"example_remain_after_logistic.csv\", index=False)\n",
        "files.download('example_remain_after_logistic.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "73a3lVaa2MnM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As before, calculate the section of the unified2_remain that has is not labeled\n",
        "bad_unified2_remain = unified2_remain.merge(example_remain, left_on=['key'], right_on=['p2.key'], how='left', indicator=True)\n",
        "bad_unified2_remain = bad_unified2_remain[bad_unified2_remain['_merge']=='left_only']\n",
        "bad_unified2_remain = bad_unified2_remain[['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']]\n",
        "print(bad_unified2_remain.shape[0])\n",
        "\n",
        "# Calculate the partner1 section of the labeled data\n",
        "example1_remain = example_remain[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "print(example1_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "afK0p9OUbQjJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Final Retouch"
      ]
    },
    {
      "metadata": {
        "id": "YSPV8x84c_KN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If it's the exact same name, it's a match"
      ]
    },
    {
      "metadata": {
        "id": "I6Hi7Tq0cS-r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "temp1 = unified1_remain.copy()\n",
        "temp2 = unified2_remain.copy()\n",
        "temp1['hotel_name2'] = temp1['hotel_name'].str.lower()\n",
        "temp1['city_name2'] = temp1['city_name'].str.lower()\n",
        "temp1['country_code2'] = temp1['country_code'].str.lower()\n",
        "temp1['hotel_address2'] = temp1['hotel_address'].str.lower()\n",
        "temp2['hotel_name2'] = temp2['hotel_name'].str.lower()\n",
        "temp2['city_name2'] = temp2['city_name'].str.lower()\n",
        "temp2['country_code2'] = temp2['country_code'].str.lower()\n",
        "temp2['hotel_address2'] = temp2['hotel_address'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjwFW6HXhanQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "same_name = pd.merge(temp1, temp2, how='inner', on=['hotel_name2', 'country_code2'])\n",
        "same_name = same_name[['key_x', 'key_y']]\n",
        "same_name.columns = ['key', 'predicted_key']\n",
        "same_name.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OWrio4N5iNcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched = matched.append(same_name)\n",
        "matched = matched.reset_index(drop=True)\n",
        "matched.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fMTu2DbGhbvW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "same_address = pd.merge(temp1, temp2, how='inner', on=['hotel_address2', 'country_code2'])\n",
        "same_address = same_address[['key_x', 'key_y']]\n",
        "same_address.columns = ['key', 'predicted_key']\n",
        "same_address.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpLFJIMLiPt1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched = matched.append(same_address)\n",
        "matched = matched.reset_index(drop=True)\n",
        "matched.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RRI7L_8lia6f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(matched[matched.duplicated(subset=['key'], keep=False)].shape[0])\n",
        "print(matched[matched.duplicated(subset=['predicted_key'], keep=False)].shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4pXWDtSi0Ef",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Drop the matched hotels from each unified1 and unified2\n",
        "unified1_remain = unified1.merge(matched, left_on=['key'], right_on=['key'], how='left', indicator=True)\n",
        "unified1_remain = unified1_remain[unified1_remain['_merge']=='left_only']\n",
        "unified1_remain.drop(columns=['_merge', 'predicted_key'], inplace=True)\n",
        "print(unified1_remain.shape[0])\n",
        "\n",
        "unified2_remain = unified2.merge(matched, left_on=['key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "unified2_remain = unified2_remain[unified2_remain['_merge']=='left_only']\n",
        "unified2_remain.drop(columns=['_merge', 'key_y', 'predicted_key'], inplace=True)\n",
        "unified2_remain = unified2_remain.rename(columns = {'key_x':'key'})\n",
        "print(unified2_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWCpVKYvi4Yv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get datapoints inside example that were not yet matched\n",
        "example_remain = example.merge(matched, left_on=['p1.key'], right_on=['key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y_-bNo79i7Dv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain = example_remain.merge(matched, left_on=['p2.key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VahdQMti8rX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As before, calculate the section of the unified2_remain that has is not labeled\n",
        "bad_unified2_remain = unified2_remain.merge(example_remain, left_on=['key'], right_on=['p2.key'], how='left', indicator=True)\n",
        "bad_unified2_remain = bad_unified2_remain[bad_unified2_remain['_merge']=='left_only']\n",
        "bad_unified2_remain = bad_unified2_remain[['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']]\n",
        "print(bad_unified2_remain.shape[0])\n",
        "\n",
        "# Calculate the partner1 section of the labeled data\n",
        "example1_remain = example_remain[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "print(example1_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MhEm0uQh3ZCz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load and Save"
      ]
    },
    {
      "metadata": {
        "id": "a6vjZGkQ3SqS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# LOADDDD\n",
        "  from google.colab import files\n",
        "  import pandas as pd\n",
        "  import io\n",
        "\n",
        "  uploaded = files.upload()\n",
        "  matched = pd.read_csv(io.StringIO(uploaded['matched_final.csv'].decode('utf-8')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejohtBw03jhL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KYQYcTOH3y6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Drop the matched hotels from each unified1 and unified2\n",
        "unified1_remain = unified1.merge(matched, left_on=['key'], right_on=['key'], how='left', indicator=True)\n",
        "unified1_remain = unified1_remain[unified1_remain['_merge']=='left_only']\n",
        "unified1_remain.drop(columns=['_merge', 'predicted_key'], inplace=True)\n",
        "print(unified1_remain.shape[0])\n",
        "\n",
        "unified2_remain = unified2.merge(matched, left_on=['key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "unified2_remain = unified2_remain[unified2_remain['_merge']=='left_only']\n",
        "unified2_remain.drop(columns=['_merge', 'key_y', 'predicted_key'], inplace=True)\n",
        "unified2_remain = unified2_remain.rename(columns = {'key_x':'key'})\n",
        "print(unified2_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xAqVCnJY34pC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get datapoints inside example that were not yet matched\n",
        "example_remain = example.merge(matched, left_on=['p1.key'], right_on=['key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AcPSr00336AR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example_remain = example_remain.merge(matched, left_on=['p2.key'], right_on=['predicted_key'], how='left', indicator=True)\n",
        "example_remain = example_remain[example_remain['_merge']=='left_only']\n",
        "example_remain.drop(columns=['key', 'predicted_key', '_merge'], inplace=True)\n",
        "example_remain.shape[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eoc4zxzE37HB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# As before, calculate the section of the unified2_remain that has is not labeled\n",
        "bad_unified2_remain = unified2_remain.merge(example_remain, left_on=['key'], right_on=['p2.key'], how='left', indicator=True)\n",
        "bad_unified2_remain = bad_unified2_remain[bad_unified2_remain['_merge']=='left_only']\n",
        "bad_unified2_remain = bad_unified2_remain[['key', 'hotel_name', 'city_name', 'country_code', 'hotel_address', 'star_rating', 'postal_code']]\n",
        "print(bad_unified2_remain.shape[0])\n",
        "\n",
        "# Calculate the partner1 section of the labeled data\n",
        "example1_remain = example_remain[['p1.key', 'p1.hotel_name', 'p1.city_name', 'p1.country_code', 'p1.hotel_address', 'p1.star_rating', 'p1.postal_code']]\n",
        "print(example1_remain.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Poi7xF1O4BX6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched.columns = [['p1.key', 'p2.key']]\n",
        "matched.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l97F-DxL4xdi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import example data to delete those points\n",
        "import pandas as pd\n",
        "downloaded = drive.CreateFile({'id':\"1JaZukEjWt_EqDVjvcmFOmdz__opIMOlw\"})   # replace the id with id of file you want to access\n",
        "downloaded.GetContentFile('example.xlsx') \n",
        "example = pd.read_excel('example.xlsx')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fXGRMDK048Xi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "example = example[['p1.key', 'p2.key']]\n",
        "example.columns = [['p1.key', 'p2.key']]\n",
        "example.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQjf4S-g7u1k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I6dlGcO_7u_q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "partner1[partner1['key']=='BD56C41BC2C68FB076F76362DEF0750D'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UnC_FCI374EU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "partner2[partner2['key']=='BD56C41BC2C68FB076F76362DEF0750D'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u_XQjYoN_5bU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Give it a try"
      ]
    },
    {
      "metadata": {
        "id": "GLbDpWaC5otC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "matched_sample = matched.sample(n=1)\n",
        "key1 = matched_sample['P1.key'].values[0]\n",
        "key2 = matched_sample['P2.key'].values[0]\n",
        "partner1[partner1['key']==key1].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rFmldnaOAEc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "partner2[partner2['key']==key2].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ebZdSmXLAWJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# SAVEEEEEE\n",
        "from google.colab import files\n",
        "caca = matched.to_csv(\"matched.csv\", index=False)\n",
        "files.download('matched.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}